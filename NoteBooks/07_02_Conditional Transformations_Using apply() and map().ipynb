{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Conditional Transformations\n",
    "\n",
    "Conditional transformations allow you to modify data values based on specified conditions, enabling dynamic updates and enhancing dataset usability for analysis and modeling.\n",
    "\n",
    "## Concept\n",
    "\n",
    "### Modifying Data Values Conditionally\n",
    "- Conditional transformations let you adjust values in a dataset based on logical conditions.\n",
    "- They are widely used for: \n",
    "  - Creating new categorical variables.\n",
    "  - Handling outliers or special cases.\n",
    "  - Applying business rules to customize data.\n",
    "\n",
    "## Topics to Cover\n",
    "### 1. Using `numpy.where()` for Conditional Value Assignments\n",
    "- A vectorized function that assigns values based on conditions.\n",
    "- Efficient for large datasets due to its speed.\n",
    "\n",
    "### 2. Using Pandas `.apply()` with Custom Conditional Logic\n",
    "- Applies custom logic row-wise or column-wise.\n",
    "- Ideal for complex transformations requiring user-defined functions.\n",
    "\n",
    "### 3. Updating Values Conditionally Within a Column\n",
    "- Directly modify values in a column based on conditions.\n",
    "- Useful for simple updates.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load a sample dataset\n",
    "data_path = '../DataSets/Data_COVID19_Indonesia.csv'\n",
    "covid_data = pd.read_csv(data_path)\n",
    "print('Dataset Preview:')\n",
    "print(covid_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `numpy.where()` for Conditional Value Assignments\n",
    "\n",
    "Suppose we want to create a new column indicating whether 'New Cases' exceed 1000.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column indicating high case counts\n",
    "covid_data['High Cases'] = np.where(covid_data['New Cases'] > 1000, 'Yes', 'No')\n",
    "print('Data with High Cases Column:')\n",
    "print(covid_data[['Date', 'New Cases', 'High Cases']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pandas `.apply()` with Custom Conditional Logic\n",
    "\n",
    "You can use `.apply()` to apply a function row-wise or column-wise for more complex conditional logic.\n",
    "\n",
    "Suppose we want to classify rows based on both 'New Cases' and 'New Deaths'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom function\n",
    "def classify_risk(row):\n",
    "    if row['New Cases'] > 1000 and row['New Deaths'] > 50:\n",
    "        return 'High Risk'\n",
    "    elif row['New Cases'] > 500:\n",
    "        return 'Moderate Risk'\n",
    "    else:\n",
    "        return 'Low Risk'\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "covid_data['Risk Level'] = covid_data.apply(classify_risk, axis=1)\n",
    "print('Data with Risk Level Column:')\n",
    "print(covid_data[['Date', 'New Cases', 'New Deaths', 'Risk Level']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating Values Conditionally Within a Column\n",
    "\n",
    "Sometimes, you may want to modify values in a column directly based on conditions.\n",
    "\n",
    "For instance, suppose we want to replace all 'High Risk' values in the 'Risk Level' column with 'Critical'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update values in the Risk Level column\n",
    "covid_data.loc[covid_data['Risk Level'] == 'High Risk', 'Risk Level'] = 'Critical'\n",
    "print('Data with Updated Risk Level:')\n",
    "print(covid_data[['Date', 'New Cases', 'New Deaths', 'Risk Level']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Conditional transformations in Pandas provide powerful tools for modifying data dynamically based on specific conditions. Techniques such as `numpy.where()`, `.apply()` with custom logic, and direct conditional updates offer flexibility and efficiency for handling diverse use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Using apply() and map()\n",
    "\n",
    "The `apply()` and `map()` methods in Pandas allow flexible and powerful transformations on DataFrames and Series, enabling the application of custom functions and logic to manipulate data efficiently.\n",
    "\n",
    "## Concept\n",
    "\n",
    "### Applying Functions to Transform Data Flexibly\n",
    "- `apply()`: Used for applying functions to rows or columns of a DataFrame, or to individual elements.\n",
    "- `map()`: Designed specifically for transforming Series objects with functions or mapping values using dictionaries.\n",
    "\n",
    "These methods are essential for dynamic and complex transformations.\n",
    "\n",
    "## Topics to Cover\n",
    "### `apply()`\n",
    "- **Row-wise and Column-wise Operations**: Use `axis=0` for columns and `axis=1` for rows.\n",
    "- **Using Custom Functions**: Apply user-defined functions for tailored operations.\n",
    "- **Applying Complex Logic**: Implement advanced transformations using Python logic and conditionals.\n",
    "\n",
    "### `map()`\n",
    "- **Transformations for Series Objects**: Apply functions to each element in a Series.\n",
    "- **Value Mapping with Dictionaries or Functions**: Map specific values to new ones using a dictionary or custom logic.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load a sample dataset\n",
    "data_path = '../DataSets/Data_COVID19_Indonesia.csv'\n",
    "covid_data = pd.read_csv(data_path)\n",
    "print('Dataset Preview:')\n",
    "print(covid_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Custom Functions Row-wise/Column-wise\n",
    "\n",
    "Using `apply()` allows you to perform transformations across rows or columns. For example, let’s calculate the ratio of 'New Cases' to 'Total Cases'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the ratio of New Cases to Total Cases\n",
    "covid_data['Case Ratio'] = covid_data.apply(lambda row: row['New Cases'] / row['Total Cases'] if row['Total Cases'] > 0 else 0, axis=1)\n",
    "print('Data with Case Ratio Column:')\n",
    "print(covid_data[['Date', 'New Cases', 'Total Cases', 'Case Ratio']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Specific Values with a Dictionary\n",
    "\n",
    "Using `map()` allows you to map specific values in a Series. For example, let’s map 'Yes' and 'No' in the 'Student' column to 1 and 0, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Yes/No to 1/0 in the Student column\n",
    "if 'Student' in covid_data.columns:  # Ensure the column exists\n",
    "    covid_data['Student Mapped'] = covid_data['Student'].map({'Yes': 1, 'No': 0})\n",
    "    print('Data with Student Mapped Column:')\n",
    "    print(covid_data[['Student', 'Student Mapped']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing Data Using a Custom Function\n",
    "\n",
    "Normalization scales values to a specific range, typically [0, 1]. Let’s normalize the 'Total Cases' column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a normalization function\n",
    "def normalize(series):\n",
    "    return (series - series.min()) / (series.max() - series.min())\n",
    "\n",
    "# Apply normalization to the Total Cases column\n",
    "covid_data['Normalized Total Cases'] = normalize(covid_data['Total Cases'])\n",
    "print('Data with Normalized Total Cases:')\n",
    "print(covid_data[['Total Cases', 'Normalized Total Cases']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The `apply()` and `map()` methods are indispensable for performing flexible and efficient data transformations in Pandas. While `apply()` is ideal for row-wise and column-wise operations, `map()` excels in transforming individual Series elements with simplicity."
   ]
  },
  {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "# 5. Best Practices and Tips\n\n",
     "Transforming data in Pandas is a critical step in data preprocessing. Following best practices ensures efficiency, reliability, and reproducibility of your transformations. Below are essential tips to keep in mind while working with data transformations.\n\n",
     "## Avoid Overwriting Original Data\n\n",
     "### Why It Matters\n",
     "- Overwriting original data can lead to data loss or unintended modifications that are difficult to trace.\n",
     "- Maintaining the integrity of the original dataset allows you to reference it if transformations need to be revisited.\n\n",
     "### How to Avoid\n",
     "- Always create a copy of the dataset before performing transformations:\n\n",
     "```python\n",
     "# Create a copy of the dataset\n",
     "transformed_data = original_data.copy()\n",
     "print(transformed_data.head())  # Preview the copied dataset\n",
     "```\n",
     "- Use `.copy()` when slicing or filtering subsets of data to avoid unintended changes:\n\n",
     "```python\n",
     "# Avoid SettingWithCopyWarning\n",
     "subset = original_data[['Column1', 'Column2']].copy()\n",
     "print(subset.head())  # Inspect the subset\n",
     "```\n\n",
     "## Performance Considerations\n\n",
     "### Why It Matters\n",
     "- Efficient operations save time and computational resources, especially with large datasets.\n",
     "- Vectorized operations in Pandas are significantly faster than Python loops.\n\n",
     "### Tips for Improved Performance\n",
     "1. **Use Vectorized Operations**:\n",
     "   - Avoid using `apply()` or `for` loops unless necessary. Instead, use built-in Pandas or NumPy functions that operate on entire Series or DataFrames.\n\n",
     "   ```python\n",
     "   # Vectorized addition\n",
     "   data['New Column'] = data['Column1'] + data['Column2']\n",
     "   print(data[['Column1', 'Column2', 'New Column']].head())\n",
     "   ```\n\n",
     "2. **Leverage NumPy for Numerical Operations**:\n",
     "   - NumPy functions are faster for numerical computations:\n\n",
     "   ```python\n",
     "   import numpy as np\n",
     "   data['Log Column'] = np.log(data['Numeric Column'])\n",
     "   print(data[['Numeric Column', 'Log Column']].head())\n",
     "   ```\n\n",
     "3. **Filter Rows and Columns Efficiently**:\n",
     "   - Use boolean indexing or `.loc[]` for filtering data:\n\n",
     "   ```python\n",
     "   filtered_data = data.loc[data['Value'] > 10, ['Column1', 'Column2']]\n",
     "   print(filtered_data.head())\n",
     "   ```\n\n",
     "## Testing Transformations\n\n",
     "### Why It Matters\n",
     "- Validating transformations ensures accuracy and prevents errors from propagating through the analysis pipeline.\n\n",
     "### How to Test Transformations\n",
     "1. **Preview Results**:\n",
     "   - Use `.head()`, `.tail()`, or `.sample()` to inspect transformed data.\n\n",
     "   ```python\n",
     "   print(data.head())\n",
     "   print(data.sample(5))  # Random sample for validation\n",
     "   ```\n\n",
     "2. **Check Data Consistency**:\n",
     "   - Use `.info()` and `.describe()` to ensure data types and statistics align with expectations.\n\n",
     "   ```python\n",
     "   print(data.info())\n",
     "   print(data.describe())\n",
     "   ```\n\n",
     "3. **Assert Expected Outcomes**:\n",
     "   - Use assertions to test specific conditions:\n\n",
     "   ```python\n",
     "   assert data['New Column'].isnull().sum() == 0, 'Missing values found in New Column'\n",
     "   assert data['Value'].max() <= 100, 'Values exceed expected range'\n",
     "   ```\n\n",
     "## Document Transformation Steps\n\n",
     "### Why It Matters\n",
     "- Clear documentation ensures reproducibility and helps others (or future you) understand the steps taken.\n",
     "- Provides a record of the transformations applied, which is especially useful in collaborative projects.\n\n",
     "### How to Document\n",
     "1. **Comment Your Code**:\n",
     "   - Add clear comments describing the purpose of each transformation:\n\n",
     "   ```python\n",
     "   # Add a column indicating high case counts\n",
     "   data['High Cases'] = np.where(data['New Cases'] > 1000, 'Yes', 'No')\n",
     "   ```\n\n",
     "2. **Use Notebooks for Analysis**:\n",
     "   - Jupyter notebooks allow combining code, markdown, and visualizations for a clear narrative:\n\n",
     "   ```python\n",
     "   print(data.head())\n",
     "   ```\n\n",
     "3. **Maintain a Change Log**:\n",
     "   - Keep track of major transformations in a separate document or notebook section.\n\n",
     "   ```markdown\n",
     "   ## Change Log\n",
     "   - Added 'High Cases' column based on 'New Cases'.\n",
     "   - Filtered data to exclude outliers.\n",
     "   ```\n\n",
     "## Conclusion\n\n",
     "Adhering to these best practices ensures that your data transformations are efficient, accurate, and reproducible. Following these tips will save time and minimize errors in your data analysis pipeline."
    ]
   }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LexLenz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
